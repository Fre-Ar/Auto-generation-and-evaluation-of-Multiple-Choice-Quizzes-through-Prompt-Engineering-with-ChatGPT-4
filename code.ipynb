{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "405eb340-e395-4cec-a1ea-734734684fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9287819-93b2-4a58-814d-d7eba8e427c4",
   "metadata": {},
   "source": [
    "# Quiz Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa895d0-4b0e-489e-a1f5-284b76958f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class representing a type of question\n",
    "class Question:\n",
    "    def __init__(self, nOccurences, topic, topicDesc, goal, learningObjective, difficulty, targetAudience, nOptions, nCorrect, allocatedTime):\n",
    "        self.nOccurences = nOccurences\n",
    "        self.topic = topic\n",
    "        self.topicDesc = topicDesc\n",
    "        self.goal = goal\n",
    "        self.learningObjective = learningObjective\n",
    "        self.difficulty = difficulty\n",
    "        self.targetAudience = targetAudience\n",
    "        self.nOptions = nOptions\n",
    "        self.nCorrect = nCorrect\n",
    "        self.allocatedTime = allocatedTime\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"Question(Occurences: {self.nOccurences}, Topic: {self.topic}, Difficulty: {self.difficulty}, Options: {self.nOptions}, Correct: {self.nCorrect})\"\n",
    "\n",
    "    def equals(self, question):\n",
    "        # Check if all attributes are equal\n",
    "        return (\n",
    "            self.topic == question.topic and\n",
    "            self.topicDesc == question.topicDesc and\n",
    "            self.goal == question.goal and\n",
    "            self.learningObjective == question.learningObjective and\n",
    "            self.difficulty == question.difficulty and\n",
    "            self.targetAudience == question.targetAudience and\n",
    "            self.nOptions == question.nOptions and\n",
    "            self.nCorrect == question.nCorrect and\n",
    "            self.allocatedTime == question.allocatedTime\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4256b7cd-f837-4145-b09b-7550d553d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that contains and manages the question types\n",
    "class QuizManager:\n",
    "    def __init__(self):\n",
    "        self.questions = []\n",
    "\n",
    "    # adds a question type to the list of questions\n",
    "    def addQuestion(self, question, count=1):\n",
    "        for q in self.questions:\n",
    "            if question.equals(q):\n",
    "                q.nOccurences += question.nOccurences\n",
    "                return\n",
    "        self.questions.append(question)\n",
    "\n",
    "    # removes a question type from the list of questions based on its index\n",
    "    def removeQuestion(self, index):\n",
    "        if index < len(self.questions):\n",
    "            del self.questions[index]\n",
    "        else:\n",
    "            print(\"Invalid question index.\")\n",
    "\n",
    "    # lists all the added question types\n",
    "    def listQuestions(self):\n",
    "        for idx, question in enumerate(self.questions):\n",
    "            print(f\"{idx}: {question}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22da3dbf-8bce-45ef-8ba8-fe808dfd1c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc5da15015f4c45b8408b5212c14907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Text(value='', description='Topic:'), Textarea(value='', description='Topic Desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Creates the Jupyter GUI to interact with (add, remove, list) the questions\n",
    "def interactWithQuizManager(quizManager):\n",
    "    #creates an visual output to display the list of question\n",
    "    questionListOutput = widgets.Output()\n",
    "\n",
    "    # callback function for when the add button is clicked\n",
    "    def addQuestion(button):\n",
    "        with questionListOutput:\n",
    "            clear_output()\n",
    "            # creates a question type based on the values of the input\n",
    "            question = Question(int(countInput.value),topicInput.value, topicDescInput.value, goalInput.value,\n",
    "                                learningObjectiveInput.value, difficultyInput.value,\n",
    "                                targetAudienceInput.value, int(nOptionsInput.value),\n",
    "                                int(nCorrectInput.value), allocatedTimeInput.value)\n",
    "            # adds that question to the quiz manager\n",
    "            quizManager.addQuestion(question)\n",
    "            #updates the index input\n",
    "            indexInput.max=len(quizManager.questions)-1\n",
    "            print(\"Question added successfully.\")\n",
    "            \n",
    "            # updates the displayed list of questions\n",
    "            quizManager.listQuestions()\n",
    "\n",
    "    # callback function for when the remove button is clicked\n",
    "    def removeQuestion(button):\n",
    "        with questionListOutput:\n",
    "            clear_output()\n",
    "            try:\n",
    "                # removes question type based on its index (value of the index input)\n",
    "                index = int(indexInput.value)\n",
    "                quizManager.removeQuestion(index)\n",
    "                print(f\"Removed question at index {index}.\")\n",
    "            except ValueError:\n",
    "                print(\"Please enter a valid integer for the question index.\")\n",
    "            except IndexError:\n",
    "                print(\"Invalid index. Please enter a correct question index.\")\n",
    "            quizManager.listQuestions()\n",
    "\n",
    "    # style of the labels of the inputs\n",
    "    st = {'description_width': 'initial'}\n",
    "    # Inputs\n",
    "    topicInput = widgets.Text(description=\"Topic:\", style=st)\n",
    "    topicDescInput = widgets.Textarea(description=\"Topic Description:\", style=st)\n",
    "    goalInput = widgets.Dropdown(description=\"Level of Bloom's taxonomy\", \n",
    "                                  options=[\"Remember\", \"Understand\", \"Apply\",\"Analyze\",\"Evaluate\",\"Create\"], value=\"Understand\", style=st)\n",
    "    learningObjectiveInput = widgets.Text(description=\"Learning Objective:\", style=st)\n",
    "    difficultyInput = widgets.Dropdown(description=\"Difficulty of the MCQ\", \n",
    "                                        options=[\"Beginner\", \"Intermediate\", \"Advanced\"], value=\"Intermediate\", style=st)\n",
    "    targetAudienceInput = widgets.Textarea(description=\"Audience:\", style=st)\n",
    "    nOptionsInput = widgets.IntSlider(description=\"Number of options per question:\", value=4,min=2,max=6, style=st)\n",
    "    nCorrectInput = widgets.IntSlider(description=\"Number of correct answers per question:\", value=1,min=1,max=6, style=st)\n",
    "    allocatedTimeInput = widgets.Text(description=\"Allocated time:\", style=st)\n",
    "\n",
    "    # Add button inputs\n",
    "    countInput = widgets.IntSlider(min=1, max=20, value=1, description=\"Number of Questions to add:\", style=st)\n",
    "    addButton = widgets.Button(description=\"Add Question\")\n",
    "    addButton.on_click(addQuestion)\n",
    "\n",
    "    # Remove button inputs\n",
    "    indexInput = widgets.IntSlider(min=0, max=min(0,len(quiz_manager.questions)), value=0, description=\"Remove Index:\", style=st)\n",
    "    removeButton = widgets.Button(description=\"Remove Question\")\n",
    "    removeButton.on_click(removeQuestion)\n",
    "\n",
    "    # layout of the GUI\n",
    "    L = widgets.Layout(width='33%')\n",
    "    inputColumn = widgets.VBox([topicInput, topicDescInput, goalInput, learningObjectiveInput,\n",
    "                           difficultyInput, targetAudienceInput, nOptionsInput,\n",
    "                           nCorrectInput, allocatedTimeInput], layout=L)  \n",
    "    actionColumn = widgets.VBox([countInput, addButton, indexInput, removeButton], layout=L)  \n",
    "    displayColumn = widgets.VBox([questionListOutput], layout=L)\n",
    "    layout = widgets.HBox([inputColumn, actionColumn, displayColumn])\n",
    "\n",
    "    # display GUI\n",
    "    display(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c03baa-02c1-472c-842a-5a41a80e23be",
   "metadata": {},
   "source": [
    "# Quiz generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ffa4588-9d9e-42e3-8a08-7acc19d621aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from openai.types.chat.completion_create_params import ResponseFormat\n",
    "import json \n",
    "\n",
    "\n",
    "def promptBuilder(quizManager):\n",
    "    questions = quizManager.questions\n",
    "    \n",
    "    topicDescriptions = '\\n'.join([\"The topic of \"+q.topic+\" is described as \"+q.topicDesc+\".\" for q in questions])\n",
    "    questionDescriptions = ';\\n'.join([f\"\"\"{q.nOccurences} questions each with exactly {q.nOptions} options, {q.nCorrect} of which are correct options, with the rest of the options being distractors. \n",
    "    They should be about {q.topic}, these should target the following learning objective: {q.learningObjective}. \n",
    "    These questions should also be at the {q.goal} level in Bloom’s taxonomy, and should be suitable for {q.difficulty} level in {q.topic}, specially for {q.targetAudience} and should not take more than {q.allocatedTime} to answer.\"\"\" for q in questions])\n",
    "    \n",
    "    systemPrompt = f\"\"\"You are an expert quiz maker and especialist in {\",\".join([q.topic for q in questions])} for the purposes of learning support. \n",
    "    {topicDescriptions}\n",
    "    \n",
    "    Your task is focused on creating top quality multiple-choice question assessments. A multiple-choice question is a collection of three components (Stem, Correct Answers, Distractors), given a particular context of what the student is expected to know. The topic, as well as the context of the topic, will be provided in order to generate effective multiple-choice questions. \n",
    "    \n",
    "    The stem refers to the question the student will attempt to answer, as well as the relevant context necessary in order to answer the question. It may be in the form of a question, an incomplete statement, or a scenario. The stem should focus on assessing the specific knowledge or concept the question aims to evaluate. \n",
    "    \n",
    "    The Correct Answer(s) refers to the correct, undisputable answer(s) to the question in the stem. \n",
    "    \n",
    "    A Distractor is an incorrect answer to the question in the stem and adheres to the following properties. \n",
    "    (1) A distractor should not be obviously wrong. In other words, it must still bear relations to the stem and correct answer. \n",
    "    (2) A distractor should be phrased positively and be a true statement that does not correctly answer the stem, all while giving no clues towards the correct answer. \n",
    "    (3) Although a distractor is incorrect, it must be plausible.\n",
    "    (4) A distractor must be incorrect. It cannot be correct, or interpreted as correct by someone who strongly grasps the topic. \n",
    "    \n",
    "    Use “None of the Above” or “All of the Above” style answer choices sparingly. These answer choices have been shown to, in general, be less effective at measuring or assessing student understanding. \n",
    "    \n",
    "    Multiple-choice questions should be clear, concise, and grammatically correct statements. Make sure the questions are worded in a way that is easy to understand and does not introduce unnecessary complexity or ambiguity. Students should be able to understand the questions without confusion. The question should not be too long, and allow most students to finish in less than the given time. This means adhering to the following properties. \n",
    "    (1) Avoid using overly long sentences. \n",
    "    (2) If you refer to the same item or activity multiple times, use the same phrase each time. \n",
    "    (3) Ensure that each multiple-choice question provides full context. In other words, if a phrase or action is not part of the provided topic or topic context that a student is expected to know, then be sure to explain it briefly or consider not including it. \n",
    "    (4) Ensure that none of the distractors overlap. In other words, attempt to make each distractor reflect a different misconception on the topic, rather than a single one, if possible. \n",
    "    (5) Avoid too many clues. Do not include too many clues or hints in the answer options, which may make it too obvious for students to determine the correct answer. These options should require students to use their knowledge and reasoning to make an informed choice.\n",
    "    \n",
    "    Blooms’ Taxonomy and Action Verbs: \n",
    "    Multiple-choice questions must be well aligned to the learning objectives they are intended to assess students’ knowledge on. This implies that they must assess skills at the right cognitive level corresponding to the Bloom’s taxonomy categorization of the learning objective. Bloom’s Taxonomy offers a framework for categorizing the depth of learning, and it provides guidance on selecting appropriate action verbs when writing learning objectives. Here are the six levels of Bloom’s taxonomy and their definitions: \n",
    "    • Remember - This level involves retrieving, recognizing, and recalling relevant knowledge from long-term memory. \n",
    "    • Understand - At this level, learners construct meaning from oral, written, and graphic messages through interpreting, exemplifying, classifying, summarizing, inferring, comparing, and explaining. \n",
    "    • Apply - This level requires learners to carry out or use a procedure through executing or implementing it. \n",
    "    • Analyze - At this level, learners break material into constituent parts, determine how the parts relate to one another and to an overall structure or purpose through differentiating, organizing.\n",
    "    • Evaluate - This level involves making judgments based on criteria and standards through checking and critiquing.\n",
    "    • Create - At this level, learners put elements together to form a coherent or functional whole, or they reorganize elements into a new pattern or structure through generating.\n",
    "    \n",
    "    Difficulty levels:\n",
    "    Multiple-choice questions must be obey certain rules to make sure the difficulty of the MCQ is appropriate:\n",
    "    • Beginner - The question should be simple, the correct answer(s) should be obvious and the distractors should be easy to distinguish from the correct answer(s).\n",
    "    • Intermediate - The question should be complicated, the correct answer(s) shouldn't pose too much of a problem to figure out but the distractors should make the student second guess their choices.\n",
    "    • Advanced - The question should be complex, the correct answer(s) should be impossible to get right without good knowledge of the topic and the distractors should guessing impossible and disencourage uninformed choices.\n",
    "    \n",
    "    Output Format\n",
    "    Output your multiple-choice quiz in an easy-to-parse json dictionary format. The quiz generated should have exactly {len(questions)} questions in total. \n",
    "    The questions generated should be the following:\n",
    "    {questionDescriptions}\n",
    "    \n",
    "    Your return should be the exact json structure of the following example (if there was 1 question with 3 options, another with 2 options, and a final one with 4 options):\n",
    "    {{\n",
    "\t\"title\": str,\n",
    "\t\"questions\": [\n",
    "\t\t{{\n",
    "\t\t\t\"context\": str,\n",
    "\t\t\t\"question\": str,\n",
    "\t\t\t\"options\": \n",
    "\t\t\t\t[\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": str,\n",
    "\t\t\t\t\t\t\"correct\": boolean,\n",
    "\t\t\t\t\t\t\"feedback\": str\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": str,\n",
    "\t\t\t\t\t\t\"correct\": boolean,\n",
    "\t\t\t\t\t\t\"feedback\": str\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": str,\n",
    "\t\t\t\t\t\t\"correct\": boolean,\n",
    "\t\t\t\t\t\t\"feedback\": str\n",
    "\t\t\t\t\t}}\t\t\t\t\t\n",
    "\t\t\t\t]\n",
    "\t\t}},\n",
    "\t\t{{\n",
    "\t\t\t\"context\": str,\n",
    "\t\t\t\"question\": str,\n",
    "\t\t\t\"options\": \n",
    "\t\t\t\t[\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": str,\n",
    "\t\t\t\t\t\t\"correct\": boolean,\n",
    "\t\t\t\t\t\t\"feedback\": str\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": str,\n",
    "\t\t\t\t\t\t\"correct\": boolean,\n",
    "\t\t\t\t\t\t\"feedback\": str\n",
    "\t\t\t\t\t}}\t\t\t\t\n",
    "\t\t\t\t]\n",
    "\t\t}},\n",
    "\t\t{{\n",
    "\t\t\t\"context\": str,\n",
    "\t\t\t\"question\": str,\n",
    "\t\t\t\"options\": \n",
    "\t\t\t\t[\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": str,\n",
    "\t\t\t\t\t\t\"correct\": boolean,\n",
    "\t\t\t\t\t\t\"feedback\": str\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": str,\n",
    "\t\t\t\t\t\t\"correct\": boolean,\n",
    "\t\t\t\t\t\t\"feedback\": str\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": str,\n",
    "\t\t\t\t\t\t\"correct\": boolean,\n",
    "\t\t\t\t\t\t\"feedback\": str\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": str,\n",
    "\t\t\t\t\t\t\"correct\": boolean,\n",
    "\t\t\t\t\t\t\"feedback\": str\n",
    "\t\t\t\t\t}}\t\t\t\t\t\n",
    "\t\t\t\t]\n",
    "\t\t}}\n",
    "\t]\t\t\n",
    "}}\n",
    "    \n",
    "    Below are some examples:\n",
    "    Example 1 (\n",
    "    - 2 questions each with exactly 4 options, 1 of which are correct options, with the rest of the options being distractors. \n",
    "    They should be about Generative AI and LLMs, these should target the following learning objective: Teaching about the topic, not testing knowledge of skills. \n",
    "    These questions should also be at the Remember level in Bloom’s taxonomy, and should be suitable for Beginner level in Generative AI and LLMs, specially for adults who have little to no knowledge about technologies and AI and should not take more than 1 minute to answer.;\n",
    "    - 1 questions each with exactly 4 options, 2 of which are correct options, with the rest of the options being distractors. \n",
    "    They should be about Generative AI and LLMs, these should target the following learning objective: Teaching about the topic, not testing knowledge of skills. \n",
    "    These questions should also be at the Remember level in Bloom’s taxonomy, and should be suitable for Beginner level in Generative AI and LLMs, specially for adults who have little to no knowledge about technologies and AI and should not take more than 1 minute to answer.) : \n",
    "    \n",
    "    {{\n",
    "\t\"title\": \"MCQ about AI for Beginner's\",\n",
    "\t\"questions\": [\n",
    "\t\t{{\n",
    "\t\t\t\"context\": \"AI, GPT, and LLM are often used interchangeably nowadays.\",\n",
    "\t\t\t\"question\": \"What does \"LLM\" stand for in the context of AI?\",\n",
    "\t\t\t\"options\":\n",
    "\t\t\t\t[\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Large Language Model\",\n",
    "\t\t\t\t\t\t\"correct\": true,\n",
    "\t\t\t\t\t\t\"feedback\": \"LLMs are trained on huge sets of data, so they are \"large\". They are a computer program trying to immitate (or \"model\") human \"language\" generation and processing.\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Long Local Machine\",\n",
    "\t\t\t\t\t\t\"correct\": false,\n",
    "\t\t\t\t\t\t\"feedback\": \"Good try, but while LLMs are a piece of technology, they are not physical machines.\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Long-term Learning Module\",\n",
    "\t\t\t\t\t\t\"correct\": false,\n",
    "\t\t\t\t\t\t\"feedback\": \"Good try, LLMs do indeed learn and are planned to last do so continuously for a long time, what distinguises LLMs is their size and natural language capabilities.\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Limited Liability Management\",\n",
    "\t\t\t\t\t\t\"correct\": false,\n",
    "\t\t\t\t\t\t\"feedback\": \"Fortunately, AIs and LLMs have nothing to do with coorporate companies... for now.\"\n",
    "\t\t\t\t\t}}\t\t\t\t\t\t\n",
    "\t\t\t\t]\n",
    "\t\t}},\n",
    "\t\t{{\n",
    "\t\t\t\"context\": \"There's been a lot of talk in the media about the impact of using Generative AI in nefarious ways.\"\n",
    "\t\t\t\"question\": \"Why is it important to use Generative AI responsibly?\",\n",
    "\t\t\t\"options\": \n",
    "\t\t\t\t[\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"To avoid spreading misinformation.\",\n",
    "\t\t\t\t\t\t\"correct\": true,\n",
    "\t\t\t\t\t\t\"feedback\": \"Generative AI models can generate convincing text that could be mistaken for factual information, so it's important to fact check anything generated by AIs!\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"To ensure it does not replace human jobs.\",\n",
    "\t\t\t\t\t\t\"correct\": false,\n",
    "\t\t\t\t\t\t\"feedback\": \"While concerns about AI and automation affecting employment exist, the primary reason for using Generative AI responsibly is not specifically about job replacement. It's more about ethical use, accuracy, and the potential impact on society, such as spreading misinformation or ethical concerns in its applications.\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"To make sure it can only play video games.\",\n",
    "\t\t\t\t\t\t\"correct\": false,\n",
    "\t\t\t\t\t\t\"feedback\": \"The scope of Generative AI extends far beyond just playing video games. The importance of using Generative AI responsibly relates to its broader applications, including content creation, decision-making support, and more. The focus on responsible use is about preventing misuse and ensuring ethical considerations in its diverse applications, not limiting it to entertainment purposes.\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"To prevent it from becoming too powerful.\",\n",
    "\t\t\t\t\t\t\"correct\": false,\n",
    "\t\t\t\t\t\t\"feedback\": \"The notion of AI becoming \"too powerful\" is a speculative and sci-fi scenario. The concern in the real world focuses on ensuring that AI is developed and used in ways that are ethical, fair, and do not harm society, rather than a fear of AI gaining autonomous power or control.\"\n",
    "\t\t\t\t\t}}\t\t\t\t\t\n",
    "\t\t\t\t]\n",
    "\t\t}},\n",
    "        {{\n",
    "\t\t\t\"context\":\"\"\n",
    "\t\t\t\"question\": \"Which of the following is an example of Generative AI's capabilities?\",\n",
    "\t\t\t\"options\": \n",
    "\t\t\t\t[\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Generating a news article based on a headline.\",\n",
    "\t\t\t\t\t\t\"correct\": true,\n",
    "\t\t\t\t\t\t\"feedback\": \"Generative AI can analyze the context and content implied by a headline and then produce a comprehensive news article that aligns with the style, tone, and factual requirements suggested by that headline. This capability demonstrates its ability to understand and generate contextually relevant text.\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Creating realistic video game environment art.\",\n",
    "\t\t\t\t\t\t\"correct\": true,\n",
    "\t\t\t\t\t\t\"feedback\": \"Generative AI can learn from vast amounts of data on landscapes, architectural styles, and environmental elements to create new, realistic video game environments. This process involves understanding the principles of design and environmental coherence to generate visually appealing and contextually suitable game worlds.\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Solving mathematical equations.\",\n",
    "\t\t\t\t\t\t\"correct\": false,\n",
    "\t\t\t\t\t\t\"feedback\": \" Solving mathematical equations typically involves computational and algorithmic approaches rather than generative processes. Generative AI focuses on creating new content based on learned patterns rather than solving structured, rule-based problems.\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Running physical simulations for engineering projects.\",\n",
    "\t\t\t\t\t\t\"correct\": false,\n",
    "\t\t\t\t\t\t\"feedback\": \"Running physical simulations involves computational models that predict how physical systems behave under various conditions, which is more about calculation and analysis rather than generating new, creative content. This task is typically handled by specialized simulation software, not generative AI.\"\n",
    "\t\t\t\t\t}}\t\n",
    "\t\t\t\t]\n",
    "\t\t}},\n",
    "  ]\n",
    "\t\t\n",
    "}}\n",
    "\n",
    "    Example 2 (\n",
    "    - 2 questions each with exactly 3 options, 1 of which are correct options, with the rest of the options being distractors. \n",
    "    They should be about French History during the Napoleonic Wars, these should target the following learning objective: Testing basic french history knowledge. \n",
    "    These questions should also be at the Remember level in Bloom’s taxonomy, and should be suitable for Intermediate level in French History during the Napoleonic Wars, specially for high school students who have studied a history class chapter on French History and should not take more than 1 minute to answer.;\n",
    "    - 1 questions each with exactly 3 options, 1 of which are correct options, with the rest of the options being distractors. \n",
    "    They should be about women in french history, these should target the following learning objective: Teach about important french female historical figures.\n",
    "    These questions should also be at the Understand level in Bloom’s taxonomy, and should be suitable for Beginner level in women in french history, specially for high school students who have studied a history class chapter on French History and should not take more than 1 minute to answer.) : \n",
    "    - 1 questions each with exactly 3 options, 1 of which are correct options, with the rest of the options being distractors. \n",
    "    They should be about historical French landmarks, these should target the following learning objective: Test knowledge about the eiffel tower and other french monuments.\n",
    "    These questions should also be at the Understand level in Bloom’s taxonomy, and should be suitable for Beginner level in historical French landmarks, specially for high school students who have studied a history class chapter on French History and should not take more than 1 minute to answer.) : \n",
    "\n",
    "{{\n",
    "\t\"title\": \"French History: Napoleon and other historical figures\",\n",
    "\t\"questions\": [\n",
    "\t\t{{\n",
    "\t\t\t\"context\": \"\",\n",
    "\t\t\t\"question\": \"Which battle was Napoleon I’s final defeat?\",\n",
    "\t\t\t\"options\": \n",
    "\t\t\t\t[\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Battle of Waterloo\",\n",
    "\t\t\t\t\t\t\"correct\": true,\n",
    "\t\t\t\t\t\t\"feedback\": \"The Battle of Waterloo (June 18, 1815) was Napoleon I's final defeat, ending 23 years of recurrent warfare between France and the other powers of Europe. It was fought between Napoleon's 72,000 troops and the combined forces of the duke of Wellington's allied army of 68,000 (with British, Dutch, Belgian, and German units) and about 45,000 Prussians, the main force of Gebhard Leberecht von Blücher's command. Four days later Napoleon abdicated for the second time.\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Battle of Agincourt\",\n",
    "\t\t\t\t\t\t\"correct\": false,\n",
    "\t\t\t\t\t\t\"feedback\": \"The Battle of Agincourt took place on October 25, 1415, and was a major English victory over the French in the Hundred Years' War. This battle occurred nearly 400 years before Napoleon I's time and is notable for the use of the English longbow, which decimated the French knights and nobility. This makes it unrelated to Napoleon I's military campaigns and final defeat.\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Battle of Verdun\",\n",
    "\t\t\t\t\t\t\"correct\": false,\n",
    "\t\t\t\t\t\t\"feedback\": \"The Battle of Verdun, fought from February to December 1916 during World War I, was one of the longest and most devastating battles in world history. It involved French and German forces in a brutal conflict with enormous casualties on both sides. Since this battle took place nearly a century after Napoleon I's death, it could not represent his final defeat.\"\n",
    "\t\t\t\t\t}}\t\t\t\t\t\t\n",
    "\t\t\t\t]\n",
    "\t\t}},\n",
    "\t\t{{\n",
    "\t\t\t\"context\": \"\",\n",
    "\t\t\t\"question\": \"What French author’s father was a general for Napoleon and was nicknamed \\“the Black Devil\\”?\",\n",
    "\t\t\t\"options\": \n",
    "\t\t\t\t[\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Alexandre Dumas\",\n",
    "\t\t\t\t\t\t\"correct\": true,\n",
    "\t\t\t\t\t\t\"feedback\": \"Alexandre Dumas is well known for classics like The Three Musketeers, but his father Thomas-Alexandre Dumas was famous in his own right. The child of an enslaved Haitian and a white Frenchman, the elder Dumas joined the French army, rose through the ranks, and became France’s first Black general. The author Dumas is said to have based some of the action in his novels on his father’s exploits.\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Victor Hugo\",\n",
    "\t\t\t\t\t\t\"correct\": false,\n",
    "\t\t\t\t\t\t\"feedback\": \"Victor Hugo, the illustrious author of Les Misérables and The Hunchback of Notre-Dame, had a father who served as a high-ranking officer under Napoleon. However, Hugo's father, Joseph Léopold Sigisbert Hugo, was not known as \"the Black Devil.\" Instead, Hugo's works often reflect his complex views on society, justice, and humanity, rather than direct inspiration from his father's military career. This distinguishes him from Alexandre Dumas, whose father's legendary military exploits directly influenced his storytelling.\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Albert Camus\",\n",
    "\t\t\t\t\t\t\"correct\": false,\n",
    "\t\t\t\t\t\t\"feedback\": \"Albert Camus, a philosopher and writer known for his contributions to absurdism and existentialism, was born in Algeria to a French-Algerian (Pied-Noir) family. His father, Lucien Camus, died in World War I, long after Napoleon's era, and had no historical ties to Napoleon's military campaigns. Camus is celebrated for works like The Stranger and The Plague, which explore the human condition and morality, unrelated to the Napoleonic military legacy.\"\n",
    "\t\t\t\t\t}}\t\t\t\t\t\t\n",
    "\t\t\t\t]\n",
    "\t\t}},\n",
    "\t\t{{\n",
    "\t\t\t\"context\": \"\",\n",
    "\t\t\t\"question\": \"Which of these French women was charged with the crime of wearing men’s clothing?\",\n",
    "\t\t\t\"options\": \n",
    "\t\t\t\t[\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Joan of Arc\",\n",
    "\t\t\t\t\t\t\"correct\": true,\n",
    "\t\t\t\t\t\t\"feedback\": \"Joan of Arc was a peasant girl who became a great military leader for France, defeating the English at Orléans in 1429. Unfortunately, she ran afoul of religious authorities by claiming God spoke directly to her (undermining the church) and wearing men’s clothing. She was convicted of heresy and burned at the stake. Decades later the conviction was overturned. In the 20th century she was made a saint.\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Marie-Antoinette\",\n",
    "\t\t\t\t\t\t\"correct\": false,\n",
    "\t\t\t\t\t\t\"feedback\": \"Marie-Antoinette, the last Queen of France before the French Revolution, was known for her extravagant lifestyle and the famous misquote \"Let them eat cake.\" However, she was never charged with the crime of wearing men’s clothing. Her charges during her trial in 1793 were related to treason, depletion of the national treasury, and conspiracy against the security of the state, not her attire. This makes her an incorrect choice for this question.\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Marie Curie\",\n",
    "\t\t\t\t\t\t\"correct\": false,\n",
    "\t\t\t\t\t\t\"feedback\": \"Marie Curie was a renowned physicist and chemist, famous for her research on radioactivity and as the first woman to win a Nobel Prize. At no point was Marie Curie charged with the crime of wearing men’s clothing. Her professional and personal life was scrutinized for her scientific contributions and personal relationships, not her fashion choices.\"\n",
    "\t\t\t\t\t}}\t\t\t\t\t\t\n",
    "\t\t\t\t]\n",
    "\t\t}},\n",
    "\t\t{{\n",
    "\t\t\t\"context\":\"\",\n",
    "\t\t\t\"question\": \"Which of these French landmarks was designed to be taken down after 20 years?\",\n",
    "\t\t\t\"options\": \n",
    "\t\t\t\t[\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Eiffel Tower.\",\n",
    "\t\t\t\t\t\t\"correct\": true,\n",
    "\t\t\t\t\t\t\"feedback\": \"The Eiffel Tower was constructed for the International Exposition of 1889. Paris gave Gustave Eiffel use of the land the tower stood on for 20 years. Fortunately, the structure was able to prove its usefulness as an antenna in the blossoming field of radio, and in 1910 the lease was renewed for 70 years.\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Louvre Museum.\",\n",
    "\t\t\t\t\t\t\"correct\": false,\n",
    "\t\t\t\t\t\t\"feedback\": \"Originally a 12th-century fortress, the Louvre was never intended to be temporary. It evolved into a world-renowned museum, housing iconic art like the Mona Lisa, showcasing its permanent significance in French heritage.\"\n",
    "\t\t\t\t\t}},\n",
    "\t\t\t\t\t{{\n",
    "\t\t\t\t\t\t\"option\": \"Arc de Triomphe.\",\n",
    "\t\t\t\t\t\t\"correct\": false,\n",
    "\t\t\t\t\t\t\"feedback\": \"Commissioned by Napoleon to honor military achievements, the Arc de Triomphe was completed in 1836 and designed as a permanent monument, not a temporary structure.\"\n",
    "\t\t\t\t\t}}\t\n",
    "\t\t\t\t]\n",
    "\t\t}}\n",
    "\t]\t\n",
    "}}\n",
    "    \n",
    "    \"\"\"  \n",
    "\n",
    "    userPrompt = f\"\"\"Generate a top quality quiz with {len(questions)} multiple-choice questions that follow this:\n",
    "    {questionDescriptions}\n",
    "    \"\"\"\n",
    "    \n",
    "    return (systemPrompt, userPrompt)\n",
    "\n",
    "# sends prompt to the OpenAI API with the prompt from the promptBuilder\n",
    "# and writes the .json file into the specified file.\n",
    "# @params: \n",
    "# - promptBuild: a tuple (system prompt, user prompt)\n",
    "# - fileNameToWrite: the name of the file into which to write the ChatGPT output\n",
    "def generateQuiz(promptBuild, fileNameToWrite):\n",
    "    client = OpenAI()\n",
    "    # tell the API to output a valid JSON file as output\n",
    "    responseFormat = ResponseFormat(type=\"json_object\")\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    response_format=responseFormat,\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": promptBuild[0]},\n",
    "            {\"role\": \"user\", \"content\": promptBuild[1]}\n",
    "        ]\n",
    "    )\n",
    "    output = completion.choices[0].message\n",
    "    content = output.content\n",
    "    \n",
    "    # write the output onto the specified file\n",
    "    with open(fileNameToWrite, 'w') as file:\n",
    "        file.write(content)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236beced-b715-4704-936f-15f958aa6494",
   "metadata": {},
   "source": [
    "# Quiz taking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a21d6c7b-b2e1-4e6d-8f2e-27726407ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import json\n",
    "\n",
    "# loads a JSON file and returns a corresponding dictionary\n",
    "def loadQuiz(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        quizData = json.load(file)\n",
    "    return quizData\n",
    "\n",
    "# displays the quiz dictionary with Jupyter widgets\n",
    "# and displays feeeback upon submission\n",
    "def displayQuiz(quizData):\n",
    "    # creating the Jupyter widgets\n",
    "    submitButton = widgets.Button(description=\"Submit Quiz\")\n",
    "    questionsOutput = widgets.Output()\n",
    "    feedbackOutput = widgets.Output()\n",
    "\n",
    "    # a list of tuples of (widget list, option list, question text) for each question\n",
    "    questionsWidgets = []\n",
    "    # for each question\n",
    "    for question in quizData['questions']:\n",
    "        with questionsOutput:\n",
    "            # print the question and its context\n",
    "            print(\"\\n\"+question['context'])#+\"\\n\"\n",
    "            print(question['question'])\n",
    "            # create a list of checkbox widgets representing the options of the question\n",
    "            options = [widgets.Checkbox(description=option['option'], \n",
    "                                        value=False, indent=False) for option in question['options']]\n",
    "            # add a tuple to the list for later use\n",
    "            questionsWidgets.append((options,\n",
    "                                     question['options'],\n",
    "                                     question['question']))\n",
    "            # display the options of the question\n",
    "            for option in options:\n",
    "                display(option)\n",
    "\n",
    "    # callback function for when the submit button is clicked\n",
    "    def onSubmit(b):\n",
    "        with feedbackOutput:\n",
    "            clear_output()\n",
    "            # feedback text container\n",
    "            feedbackHtml = \"\"\n",
    "            # for each question\n",
    "            for optionWidgets, questionData, questionText in questionsWidgets:\n",
    "                # write the question text to the feecback container\n",
    "                feedbackHtml += f\"<div><strong>{question_text}</strong></div>\"\n",
    "                # for each option\n",
    "                for optionWidget, optionData in zip(optionWidgets, questionData):\n",
    "                    # if the option is checked...\n",
    "                    if optionWidget.value:\n",
    "                        # and is a correct answer\n",
    "                        if optionData['correct']:\n",
    "                            # write the feedback explaining why it is correct (coloured green)\n",
    "                            feedbackHtml += f\"<div style='color: green; font-weight: bold;'>Selected: \n",
    "                                            {optionData['option']} - Feedback: {optionData['feedback']}</div>\"\n",
    "                        # and is an incorrect answer\n",
    "                        else:\n",
    "                            # write the feedback explaining why it is incorrect (coloured red)\n",
    "                            feedbackHtml += f\"<div style='color: red; font-weight: bold;'>Selected: \n",
    "                                            {optionData['option']} - Feedback: {optionData['feedback']}</div>\"\n",
    "                    # if the option isn't checked but is a correct answer\n",
    "                    elif optionData['correct']:\n",
    "                        # write the feedback why it is correct \n",
    "                        # (coloured orange to signify it was a missed correct answer)\n",
    "                        feedbackHtml += f\"<div style='color: orange; font-weight: bold;'>Missed: \n",
    "                                        {optionData['option']} - Feedback: {optionData['feedback']}</div>\"\n",
    "            # display the feedback text container\n",
    "            display(HTML(feedbackHtml))\n",
    "            # disable all widgets of the quiz (the quiz is submitted, so it's over)\n",
    "            submitButton.disabled = True\n",
    "            for options, _, _ in questionsWidgets:\n",
    "                for option in options:\n",
    "                    option.disabled = True\n",
    "                    \n",
    "    # add callback function to button\n",
    "    submitButton.on_click(onSubmit)\n",
    "    # display the quiz\n",
    "    display(questionsOutput)\n",
    "    display(submitButton)\n",
    "    display(feedbackOutput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791a00a-48e3-4559-9082-7d34325c006e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
